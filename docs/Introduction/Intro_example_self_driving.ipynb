{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99323cf",
   "metadata": {},
   "source": [
    "# CPS Example: Autonomous Vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986634da",
   "metadata": {},
   "source": [
    "Another prime example of a CPS is the [*autonomous vehicle*](https://en.wikipedia.org/wiki/Self-driving_car), or a *self-driving* car, capable of operating with reduced or **no** human input. In other words, autonomous vehicles are responsible for all driving activities, such as perceiving the environment, monitoring important systems, and controlling the vehicle, which includes navigating from origin to destination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c0e39a",
   "metadata": {},
   "source": [
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ypj2ii--1Uc?si=rmp1W34az_HOcKyE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "\n",
    "A BBC News video about self-driving trucks (The direct link to YouTube [video](https://youtu.be/ypj2ii--1Uc?si=w-NV3RrCVip-LEQN), accessed September 9, 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13461a0",
   "metadata": {},
   "source": [
    "In order to *perceive the environment*, the autonomous vehicle is equipped with a set of sensors:\n",
    "- [LiDar](https://en.wikipedia.org/wiki/Lidar): or *Light Detection and Ranging*, is a method for determining ranges by targeting an object or a surface with a laser and measuring the [time for the reflected light](https://en.wikipedia.org/wiki/Time_of_flight) to return to the receiver. It creates detailed three-dimensional point clouds of the surrounding environment by measuring distances using laser pulses, providing precise spatial mapping *even* in low-light conditions,\n",
    "- [Ultrasound](https://en.wikipedia.org/wiki/Ultrasound): instead of light, uses sound wave instead to provide short-range proximity detection for close-quarters manoeuvring such as parking. It also works using the principle of [time-of-flight](https://en.wikipedia.org/wiki/Time_of_flight). The sensors are typically mounted in bumpers to detect neary obstacles,\n",
    "- [Radar](https://en.wikipedia.org/wiki/Radar): uses radio waves to determine the distance (ranging), direction, and velocity of objects relative to the vehicle. It can operate reliably in adverse weather conditions such as fog, rain, or snow,\n",
    "- Cameras: Capture visual information for object recognition, traffic sign interpretation, lane detection, and traffic light status, typically deployed as stereo pairs or arrays to provide depth perception. The captured images are nowadays processed using machine-learning techniques with real-time performance.\n",
    "- GPS (Global Positioning System): Enables global localization and navigation, often augmented with differential GPS or real-time kinematic positioning for centimetre-level accuracy,\n",
    "- Inertial Measurement Units (IMUs): Measure vehicle acceleration, angular velocity, and orientation using accelerometers and gyroscopes, providing essential data for vehicle dynamics and sensor fusion,\n",
    "- Wheel encoders: Monitor wheel rotation to calculate vehicle speed and distance travelled, contributing to odometry calculations,\n",
    "- Thermal cameras: Detect heat signatures to identify pedestrians, animals, or other warm objects, particularly useful in low-visibility conditions or at night."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1d103",
   "metadata": {},
   "source": [
    "The **cyber component** of an autonomous vehicle consists of sophisticated **machine learning algorithms** and **computer vision systems** that process this sensory data in real-time. For example, **visual perception** takes the video feed from the cameras as inputs, and identifies and classifies objects such as pedestrians, other vehicles, road signs, and lane marking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d638d",
   "metadata": {},
   "source": [
    "**Perception modules** identify and classify objects such as pedestrians, other vehicles, road signs, and lane markings, while **prediction algorithms** anticipate the future behaviour of dynamic objects in the environment. **Path planning systems** generate safe, efficient trajectories that respect traffic rules and minimize collision risk, while **control algorithms** translate these high-level plans into specific steering, acceleration, and braking commands.\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/HS1wV9NMLr8?si=u82k2KuFqDB3M4rc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "\n",
    "An nVidia video demonstrating visual perception for autonomous vehicle (The direct link to YouTube [video](https://blogs.nvidia.com/blog/drive-labs-panoptic-segmentation/), accessed September 9, 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb3d35f",
   "metadata": {},
   "source": [
    "The **physical component** encompasses the vehicle's mechanical systems: \n",
    "- The **steering actuators** that precisely control wheel angle, \n",
    "- The **brake systems** that modulate stopping force,\n",
    "- The **throttle controls** that regulate engine power or electric motor output, and \n",
    "- The **vehicle dynamics** governed by physics including momentum, friction, and aerodynamics. \n",
    "\n",
    "The **tight coupling** between cyber and physical domains becomes evident in how computational decisions must account for physical constraints—braking distances, turning radii, and acceleration limits—while physical sensor measurements directly influence computational processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305c6a3",
   "metadata": {},
   "source": [
    "**[Vehicle-to-everything](https://en.wikipedia.org/wiki/Vehicle-to-everything) (V2X) communication** represents the **networking aspect** of automotive CPS, enabling cars to exchange information with other vehicles, traffic infrastructure, and cloud-based services. It describes *wireless* communication between a vehicle and any entity that may affect, or may be affected by, the vehicle.\n",
    "\n",
    "This connectivity allows individual vehicles to benefit from collective intelligence: traffic light timing information can optimize fuel efficiency, hazard warnings from other vehicles can improve safety, and real-time traffic data can inform routing decisions. It is intended to improve road safety and traffic efficienty while reduging pollution and saving energy.\n",
    "\n",
    " The **distributed nature** of this system means that intelligence resides not only within individual vehicles but also across the broader transportation network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c14be",
   "metadata": {},
   "source": [
    "The **real-time constraints** in autonomous vehicles are particularly stringent, as delayed responses can have **life-threatening consequences**. Emergency braking decisions must be executed within milliseconds, while navigation and route planning can operate on longer timescales of seconds or minutes. This creates a **multi-layered temporal architecture** where different subsystems operate at different frequencies while maintaining overall system coherence.\n",
    "\n",
    "Perhaps most importantly, autonomous vehicles demonstrate how cyber-physical systems must handle **uncertainty and incomplete information**. Unlike controlled laboratory environments, real-world driving involves unpredictable human behaviour, varying weather conditions, construction zones, and novel scenarios not encountered during system training. The vehicle's ability to operate safely under these conditions emerges from the **continuous feedback loops** between sensing, computation, and actuation, combined with **robust control algorithms** that can maintain safe operation even when individual components fail or environmental conditions exceed design parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf4a8b",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dec812",
   "metadata": {},
   "source": [
    "```{figure} ./../imgs/Introduction/robotaxis-on-the-way.avif\n",
    "---\n",
    "name: Waymo_jam\n",
    "---\n",
    "A Waymo driverless taxi stops on a street in San Francisco for several minutes because the back door was not completely shut, while traffic backs up behind it, on Feb. 15. Six months later, 10 Cruise driverless taxis stalled due to wireless bandwidth issues, causing gridlock for several blocks. (Terry Chea/The Associated Press). Image and caption courtesy of the [original CBC News article](https://www.cbc.ca/radio/asithappens/san-francisco-robotaxi-traffic-jam-1.6938440), Assessed on September 9, 2025."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
