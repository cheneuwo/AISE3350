{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99323cf",
   "metadata": {},
   "source": [
    "# CPS examples: Autonomous cleaning vacuum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d0bf5",
   "metadata": {},
   "source": [
    "![test](./../imgs/Introduction/smart-navigation-robot.jpg)\n",
    "\n",
    "[Image courtesy](https://www.aitimejournal.com/wp-content/uploads/2021/05/smart-navigation-robot.jpg), Accessed on September 9, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459f65e1",
   "metadata": {},
   "source": [
    "The **[autonomous cleaning vacuum](https://en.wikipedia.org/wiki/Robotic_vacuum_cleaner)**, commonly know as a **robotic vacuum**, is a common household item. Autonomous cleaning vaccum demonstrates how CPS principles enable machines to operate independently in *unstructured*, *dynamic* space while performing physically tasks that traditionally required human interventions. Autonomous cleaning vacuums integrate sophisticated **computational algorithms** with **mechanical cleaning systems** to navigate residential spaces, avoid obstacles, and systematically clean floor surfaces without supervision. The system continuously adapts its cleaning patterns based on real-time environmental feedback, demonstrating the **tight coupling** between cyber and physical domains that characterises modern CPS implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a6096",
   "metadata": {},
   "source": [
    "The effectiveness of autonomous cleaning vacuums depends on a comprehensive **sensor suite** that enables *perception* of the environment, including:\n",
    "- **Ultrasonic time-of-flight sensors**: akin to [parking sensors](https://en.wikipedia.org/wiki/Parking_sensor), ultrasonic sensors work in varying light conditions, independent of the target's colour and optical transparency. This type of sensor often has a wide field-of-view (FoV), allowing it to simultaneously measure the range of multiple objects. In a robot vacuum, they are used for *object detection*, such as a dog or a child's toy, such that it can manoeuvre around the obstacle to avoid a collision,\n",
    "- **[LiDAR](https://en.wikipedia.org/wiki/Lidar), or *light detection and ranging* sensors**: is a method for determining ranges by targeting an object or a surface with a laser and measuring the time for teh reflected light to return to the receivers. It is commonly used to generate a 3D representation of the environment,\n",
    "- **Camera**: sequence of images are used to constract 3D map of the environment using a technique in *computer vision* known as *[Simultaneous Localization and Mapping](https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping), or SLAM, and\n",
    "- others,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a8afa",
   "metadata": {},
   "source": [
    "The **cyber component**, similar to GPS software, processes these sensor data through path-planning algorithm, obstacle avoidance routines, and optimizes the cleaning pattern. The **physical components** executes these plans through motor controls that drives the wheels, operate the cleaning brushes, and manage suction power based on the dtected surface types (e.g. wooden floor or carpet)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
